{
  if (!closed) {
    executor.submit(new Runnable(){
      @Override public void run(){
        try {
          LOG.debug("[{}] appending {} logs to kafka collection",topicName,logEventPack.getEvents().size());
          GenericAvroConverter<GenericRecord> eventConverter=getConverter(logEventPack.getLogSchema().getSchema());
          GenericAvroConverter<GenericRecord> headerConverter=getConverter(header.getSchema().toString());
          List<KafkaLogEventDto> dtoList=generateKafkaLogEvent(logEventPack,header,eventConverter);
          LOG.debug("[{}] saving {} objects",topicName,dtoList.size());
          if (!dtoList.isEmpty()) {
            int logCount=dtoList.size();
            inputLogCount.getAndAdd(logCount);
            logEventDao.save(dtoList,eventConverter,headerConverter,new LogAppenderCallback(listener,kafkaSuccessLogCount,kafkaFailureLogCount));
            LOG.debug("[{}] appended {} logs to kafka collection",topicName,logEventPack.getEvents().size());
          }
 else {
            listener.onInternalError();
          }
        }
 catch (        Exception e) {
          LOG.warn("Got exception. Can't process log events",e);
          listener.onInternalError();
        }
      }
    }
);
  }
 else {
    LOG.info("Attempted to append to closed appender named [{}].",getName());
    listener.onConnectionError();
  }
}
